{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import re\n",
    "from opencc import OpenCC\n",
    "import jieba\n",
    "import gensim\n",
    "from time import time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###参考 https://github.com/csn6666/NLPhomework/blob/maste/assignment-4/w2v_Solutions.ipynb\n",
    "\n",
    "\n",
    "\n",
    "def get_path():\n",
    "    path=[]\n",
    "    input_file=\"C:/Users/Lenovo Y510P/Desktop/assignments/wiki/simplified\"\n",
    "    for root, dir_li_1, file_li_1 in os.walk(input_file, topdown=False):\n",
    "        for one_file in file_li_1:\n",
    "            one_file=os.path.join(root,one_file)\n",
    "            path.append(one_file)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_word():\n",
    "    with open(\"C:/Users/Lenovo Y510P/Desktop/assignments/wiki/stopwords-zh.txt\", 'r', encoding='utf8')as f:\n",
    "        stop_words=[x.strip()for x in f.readlines()]\n",
    "        return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(path, stop_words):\n",
    "    sentences_by_word = []\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        corpus = f.readlines()\n",
    "        print('Now processing:' + path)\n",
    "        for sentence in corpus:\n",
    "            sentence = ''.join(re.findall(r'\\w+', sentence))\n",
    "            if sentence == '': continue\n",
    "            words = jieba.cut(sentence)\n",
    "            sentences_by_word.append([word for word in words if word not in stop_words])\n",
    "    with open('C:/Users/Lenovo Y510P/Desktop/assignments/wiki/tra2sim/' + path[-10:-8]+ path[-7:len(path)], 'wb') as f:\n",
    "         pickle.dump(sentences_by_word, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_path()\n",
    "stop_words=get_stop_word()\n",
    "#\n",
    "for path in paths:\n",
    "    p=Process(target=get_train_data,args=(path,stop_words))\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10is loaded\n",
      "20is loaded\n",
      "30is loaded\n",
      "40is loaded\n",
      "50is loaded\n",
      "60is loaded\n",
      "70is loaded\n",
      "80is loaded\n",
      "90is loaded\n",
      "100is loaded\n",
      "110is loaded\n",
      "120is loaded\n",
      "130is loaded\n",
      "140is loaded\n",
      "150is loaded\n",
      "160is loaded\n",
      "170is loaded\n",
      "180is loaded\n",
      "190is loaded\n",
      "200is loaded\n",
      "210is loaded\n",
      "220is loaded\n",
      "230is loaded\n",
      "240is loaded\n",
      "250is loaded\n",
      "260is loaded\n",
      "270is loaded\n",
      "280is loaded\n",
      "290is loaded\n",
      "300is loaded\n",
      "310is loaded\n",
      "320is loaded\n",
      "330is loaded\n",
      "340is loaded\n",
      "350is loaded\n",
      "360is loaded\n",
      "370is loaded\n",
      "380is loaded\n",
      "390is loaded\n",
      "400is loaded\n",
      "410is loaded\n",
      "420is loaded\n",
      "430is loaded\n",
      "440is loaded\n",
      "450is loaded\n",
      "460is loaded\n",
      "470is loaded\n",
      "480is loaded\n",
      "490is loaded\n",
      "500is loaded\n",
      "510is loaded\n",
      "520is loaded\n",
      "530is loaded\n",
      "540is loaded\n",
      "550is loaded\n",
      "560is loaded\n",
      "570is loaded\n",
      "580is loaded\n",
      "590is loaded\n",
      "600is loaded\n",
      "610is loaded\n",
      "620is loaded\n",
      "630is loaded\n",
      "640is loaded\n",
      "650is loaded\n",
      "660is loaded\n",
      "670is loaded\n",
      "680is loaded\n",
      "690is loaded\n",
      "700is loaded\n"
     ]
    }
   ],
   "source": [
    "train_data=[]\n",
    "count=0\n",
    "input_file=\"C:/Users/Lenovo Y510P/Desktop/assignments/wiki/tra2sim\"\n",
    "for wikifile in os.listdir(input_file):\n",
    "    wikifile_path=os.path.join(input_file, wikifile)\n",
    "    with open(wikifile_path,'rb') as f:\n",
    "        train_data.extend(pickle.load(f))\n",
    "        count +=1\n",
    "        if count%10==0:\n",
    "            print('{}is loaded'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time()\n",
    "model = Word2Vec(train_data, size=100, window=2, min_count=20, sg=1, workers=7)\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#电脑load 数据很慢，请问是什么原因？上面 load 700份用了一上午。模型训练也是很久没有出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
